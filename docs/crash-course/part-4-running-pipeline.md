# Part 4 - Running Pipeline

You are ready to run your first train pipeline! During development, you can run a pipeline using the `run.py` file.

>Note: In a production setup, we recommend to run the pipelines via message queues.

First, open up the file **run.py**.

Modify the `configs` list by replacing `asset_name` with `crash_course`:

```python
configs = [
    {
        "asset_name": "crash_course",
        "config_path": "assets/crash_course/configs/crash_course_train_config.yaml"
    }
]
```

!!! tip "_configs_ variable in the _run.py_ file"

    `configs` is a list containing instructions for different configurations to run.
    
    Each instructions in the `configs` variable contains the following attributes:
    
    * **asset_name** (required): the name of the asset we created, in our case: `crash_course`.
    
    * **config_path** (required): path to the config file, can be a JSON file or a python file.
    
    * **config_name** (optional): if the config file is a python file, specify the name of the variable in that file here.

Finally, execute `run.py` file:
```bash
python run.py
```

By default, MLApp saves the job results in the local **output** directory at your project root directory. The output can be saved in databases and object storages once you have them configured in your environment.

If your model train job was successful, you should see the following new files in the **output** directory, prefaced with the unique `model_id` generated by the job:

!!! note "Files in Output"

    * **<run_id\>_crash_course.metadata.json**: Any static information we stored during the run of the pipeline such as the missing values and the scores.
    
    * **<run_id\>_crash_course.models.pkl.pkl**: Any run-time objects we stored during the run of the pipeline such as the model.
    
    * **<run_id\>_crash_course.config.json**: When a run is completed successfully, the configuration file is saved with the `run_id`.
    
    * **<run_id\>_<job_id\>.logger.txt**: The logs output during the training process. Can be identified by either `run_id` or `job_id`
    
    * **<job_id\>_crash_course.config.json**: The configuration of the run by `job_id` (always saved in case of pipeline failure).
    

Finally, a summary of the training process is printed in the console.

```
------------------------ Analysis Summary Print -----------------------------
Job id: <job_id>
Asset Name: crash_course
Run id: <run_id>
Current date and time: YYYY-MM-DD HH:MM:SS
Analysis started running at: YYYY-MM-DD HH:MM:SS
Elapsed Time from the beginning: <HH:MM:SS>
-----------------------------------------------------------------------------
```

Save the `run_id` as you'll need it later for forecasting.

!!! tip "output/output_logs.csv"

    This file will be created when running a pipeline locally. 
    
    It will store in a table-like structure all your local runs and the metadata output.

!!! tip "output/latest_ids.json"

    This file will be created when running a pipeline locally. It will store the latest `run_id` for any asset you ran locally.
    
    Later on, whenever a `run_id` is required, you can replace it with `latest` and it will use the latest `run_id` of the specific asset.


<br/>
Congrats, you have run a train pipeline! We can move on to [running the forecast pipeline](/crash-course/part-5-forecast-pipeline).
